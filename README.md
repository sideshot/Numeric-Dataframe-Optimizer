# Pandas DataFrame Optimizer

## Overview
This script is designed to optimize memory usage in large Pandas DataFrames. It intelligently selects the most appropriate data types for numeric columns, balancing memory efficiency with the need to represent the data accurately. This is particularly useful for large datasets, where memory management is crucial.

## Features
- **Automatic Data Type Selection**: Determines the best data type for each numeric column based on the range of values and presence of NaNs.
- **Memory Usage Reduction**: Significantly reduces the memory footprint of the DataFrame.
- **Column Removal**: Drops completely empty columns, further optimizing memory usage.

## Results
Using this script on a DataFrame with 12 million rows showed substantial improvements:
- **Runtime**: 54 seconds
- **Before Optimization**: 
  - Memory Usage: 10.5+ GB
  - Total Columns: 107
- **After Optimization**: 
  - Memory Usage: 2.9+ GB
  - Total Columns: 85

## Usage
1. Import the required libraries: `pandas` and `numpy`.
2. Define the `optimize_df` function in your script.
3. Pass your DataFrame to the `optimize_df` function.

Example:
```python
import pandas as pd
import numpy as np

# Your DataFrame
original_df = ...

optimized_df = optimize_df(original_df)
```

## Implementation Details
- The script includes functions to determine the best-fit data type for integer and floating-point columns.
- It uses a combination of NumPy and Pandas data types, choosing between standard and nullable types based on the presence of NaN values.
- The script begins by reporting the initial memory usage and ends with the optimized memory usage for easy comparison.

## Requirements
- Python 3.x
- Pandas 2.x
- NumPy

## Disclaimer
- The script assumes that the input DataFrame is well-formed and contains numeric columns that can benefit from data type optimization.
- The performance may vary based on the DataFrame's structure and content.
